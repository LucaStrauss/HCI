\chapter{Zielsetzung}

Visuell auswertbare Aufzeichnung mit zB. Microsoft Kinect Tiefensensoren sind in der HCI Forschung zur Erkennung von Bewegungsprofilen von Nutzern weit verbreitet. Ein großes Maß an Forschungs- und Entwicklungsarbeit wurde bereits in die Bereitstellungen von effektiven Open-Source L\"osungen (Erkennungsraten ~ 90\%) für die Forschung investiert \cite{Elhart}. Ein haupts\"achliches Problem visueller Auswertung mit Tiefensensor ist die Messungenauigkeit, die u.A. durch die Verdeckung von Personen entsteht. Dieser Effekt wird besonders dann deutlich, wenn Personen in Gruppen zusammen oder versetzt sich innerhalb des Sichtbereiches des Sensors bewegen. Die Verdeckung kommt bei (allen) visuellen Sensoren, insbesondere bei Kamera-unterstützen Auswertungen zum Tragen. Die Verdeckung kann bereits durch die Installation weiterer (visueller) Sensoren minimiert werden. Mit diesem Proposal soll eine alternative M\"oglichkeit zur L\"osung des „Verdeckungsfehlers“ sowie eine Erweiterung der (verf\"ugbaren) Messdaten zur Unterst\"utzung der Erkennung von Bewegungsprofilen vor \"offentlichen Bildschirmen untersucht werden. Die Idee ist, neben der visuellen Auswertung auch die Ger\"ausche der Aktivit\"aten vor einem \"offentlichen Display mit einem Mikrofon aufzuzeichnen. Die aufgenommen Audiodaten sollen erweiterte Aussagen zur Konkretisierung der Bewegungsprofile liefern.

Die erwarteten Ergebnisse sind zum einen, dass die Lautst\"arke mit der Anzahl visuell erfasster Personen korreliert. Die Lautst\"arke steigt dann zur selben Zeit mit der Anzahl der vom Tiefensensor erfassten Personen an. Diese Information kann f\"ur die Erkennung einer (visuell) verdeckten Person verwendet werden (Beispiel: 2 Personen laufen hintereinander, die hintere kann nur durch die zus\"atzliche Audiospur erkannt werden). Ein weiteres erwartetes Ergebnis ist die Korrelation des Audioprofils (Trittfrequenz) mit der Geschwindigkeit der visuell erfassten Personen. Mit Audioprofil ist die Trittfrequenz innerhalb der Audioaufzeichnungen einer oder mehrerer laufender Personen gemeint. Das Auftreten einer Person wird somit vom Mikrophon aufgezeichnet und resultiert in einem Ausschlag auf der Audiospur. Die Geschwindigkeit einer laufenden Person kann durch Analyse der Audiospur (Abstand der Auftritte auf der Audiospur) ausgewertet werden. Erwartet wird, dass die auf dem Audioprofil erkannte Trittfrequenz mit der erkannten Geschwindigkeit des Tiefensensors ansteigt. 

Insofern die Audioprofile nun belastbare Aussagen über die Anzahl der (versteckten) Personen treffen k\"onnen und ausreichend spezifisch sind, kann der Mehrwert eines zusätzlichen Audiosensors in einem HCI-Tool empirisch belegt werden.


